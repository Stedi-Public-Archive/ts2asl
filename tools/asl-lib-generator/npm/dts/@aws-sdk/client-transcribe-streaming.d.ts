// Generated by dts-bundle v0.7.3
// Dependencies for this module:
//   @aws-sdk/types
//   @aws-sdk/smithy-client
//   @aws-sdk/config-resolver
//   @aws-sdk/eventstream-serde-config-resolver
//   @aws-sdk/middleware-eventstream
//   @aws-sdk/middleware-host-header
//   @aws-sdk/middleware-retry
//   @aws-sdk/middleware-sdk-transcribe-streaming
//   @aws-sdk/middleware-signing
//   @aws-sdk/middleware-user-agent
//   @aws-sdk/protocol-http

declare module '@aws-sdk/client-transcribe-streaming' {
    import { HttpHandlerOptions as __HttpHandlerOptions } from "@aws-sdk/types";
    import { StartMedicalStreamTranscriptionCommandInput, StartMedicalStreamTranscriptionCommandOutput } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartMedicalStreamTranscriptionCommand";
    import { StartStreamTranscriptionCommandInput, StartStreamTranscriptionCommandOutput } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartStreamTranscriptionCommand";
    import { TranscribeStreamingClient } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/TranscribeStreamingClient";
    /**
        * <p>Operations and objects for transcribing streaming speech to text.</p>
        */
    export class TranscribeStreaming extends TranscribeStreamingClient {
            /**
                * <p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe Medical and the
                *             transcription results are streamed to your application.</p>
                */
            startMedicalStreamTranscription(args: StartMedicalStreamTranscriptionCommandInput, options?: __HttpHandlerOptions): Promise<StartMedicalStreamTranscriptionCommandOutput>;
            startMedicalStreamTranscription(args: StartMedicalStreamTranscriptionCommandInput, cb: (err: any, data?: StartMedicalStreamTranscriptionCommandOutput) => void): void;
            startMedicalStreamTranscription(args: StartMedicalStreamTranscriptionCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: StartMedicalStreamTranscriptionCommandOutput) => void): void;
            /**
                * <p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe and the transcription
                *       results are streamed to your application.</p>
                *          <p>The following are encoded as HTTP/2 headers:</p>
                *          <ul>
                *             <li>
                *                <p>x-amzn-transcribe-language-code</p>
                *             </li>
                *             <li>
                *                <p>x-amzn-transcribe-media-encoding</p>
                *             </li>
                *             <li>
                *                <p>x-amzn-transcribe-sample-rate</p>
                *             </li>
                *             <li>
                *                <p>x-amzn-transcribe-session-id</p>
                *             </li>
                *          </ul>
                *          <p>See the <a href="https://docs.aws.amazon.com/sdk-for-go/api/service/transcribestreamingservice/#TranscribeStreamingService.StartStreamTranscription"> SDK for Go API Reference</a> for more detail.</p>
                */
            startStreamTranscription(args: StartStreamTranscriptionCommandInput, options?: __HttpHandlerOptions): Promise<StartStreamTranscriptionCommandOutput>;
            startStreamTranscription(args: StartStreamTranscriptionCommandInput, cb: (err: any, data?: StartStreamTranscriptionCommandOutput) => void): void;
            startStreamTranscription(args: StartStreamTranscriptionCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: StartStreamTranscriptionCommandOutput) => void): void;
    }
}

declare module '@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartMedicalStreamTranscriptionCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { StartMedicalStreamTranscriptionRequest, StartMedicalStreamTranscriptionResponse } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/models/models_0";
    import { ServiceInputTypes, ServiceOutputTypes, TranscribeStreamingClientResolvedConfig } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/TranscribeStreamingClient";
    export interface StartMedicalStreamTranscriptionCommandInput extends StartMedicalStreamTranscriptionRequest {
    }
    export interface StartMedicalStreamTranscriptionCommandOutput extends StartMedicalStreamTranscriptionResponse, __MetadataBearer {
    }
    /**
        * <p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe Medical and the
        *             transcription results are streamed to your application.</p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { TranscribeStreamingClient, StartMedicalStreamTranscriptionCommand } from "@aws-sdk/client-transcribe-streaming"; // ES Modules import
        * // const { TranscribeStreamingClient, StartMedicalStreamTranscriptionCommand } = require("@aws-sdk/client-transcribe-streaming"); // CommonJS import
        * const client = new TranscribeStreamingClient(config);
        * const command = new StartMedicalStreamTranscriptionCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link StartMedicalStreamTranscriptionCommandInput} for command's `input` shape.
        * @see {@link StartMedicalStreamTranscriptionCommandOutput} for command's `response` shape.
        * @see {@link TranscribeStreamingClientResolvedConfig | config} for TranscribeStreamingClient's `config` shape.
        *
        */
    export class StartMedicalStreamTranscriptionCommand extends $Command<StartMedicalStreamTranscriptionCommandInput, StartMedicalStreamTranscriptionCommandOutput, TranscribeStreamingClientResolvedConfig> {
            readonly input: StartMedicalStreamTranscriptionCommandInput;
            constructor(input: StartMedicalStreamTranscriptionCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: TranscribeStreamingClientResolvedConfig, options?: __HttpHandlerOptions): Handler<StartMedicalStreamTranscriptionCommandInput, StartMedicalStreamTranscriptionCommandOutput>;
    }
}

declare module '@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartStreamTranscriptionCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { StartStreamTranscriptionRequest, StartStreamTranscriptionResponse } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/models/models_0";
    import { ServiceInputTypes, ServiceOutputTypes, TranscribeStreamingClientResolvedConfig } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/TranscribeStreamingClient";
    export interface StartStreamTranscriptionCommandInput extends StartStreamTranscriptionRequest {
    }
    export interface StartStreamTranscriptionCommandOutput extends StartStreamTranscriptionResponse, __MetadataBearer {
    }
    /**
        * <p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe and the transcription
        *       results are streamed to your application.</p>
        *          <p>The following are encoded as HTTP/2 headers:</p>
        *          <ul>
        *             <li>
        *                <p>x-amzn-transcribe-language-code</p>
        *             </li>
        *             <li>
        *                <p>x-amzn-transcribe-media-encoding</p>
        *             </li>
        *             <li>
        *                <p>x-amzn-transcribe-sample-rate</p>
        *             </li>
        *             <li>
        *                <p>x-amzn-transcribe-session-id</p>
        *             </li>
        *          </ul>
        *          <p>See the <a href="https://docs.aws.amazon.com/sdk-for-go/api/service/transcribestreamingservice/#TranscribeStreamingService.StartStreamTranscription"> SDK for Go API Reference</a> for more detail.</p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { TranscribeStreamingClient, StartStreamTranscriptionCommand } from "@aws-sdk/client-transcribe-streaming"; // ES Modules import
        * // const { TranscribeStreamingClient, StartStreamTranscriptionCommand } = require("@aws-sdk/client-transcribe-streaming"); // CommonJS import
        * const client = new TranscribeStreamingClient(config);
        * const command = new StartStreamTranscriptionCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link StartStreamTranscriptionCommandInput} for command's `input` shape.
        * @see {@link StartStreamTranscriptionCommandOutput} for command's `response` shape.
        * @see {@link TranscribeStreamingClientResolvedConfig | config} for TranscribeStreamingClient's `config` shape.
        *
        */
    export class StartStreamTranscriptionCommand extends $Command<StartStreamTranscriptionCommandInput, StartStreamTranscriptionCommandOutput, TranscribeStreamingClientResolvedConfig> {
            readonly input: StartStreamTranscriptionCommandInput;
            constructor(input: StartStreamTranscriptionCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: TranscribeStreamingClientResolvedConfig, options?: __HttpHandlerOptions): Handler<StartStreamTranscriptionCommandInput, StartStreamTranscriptionCommandOutput>;
    }
}

declare module '@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/TranscribeStreamingClient' {
    import { EndpointsInputConfig, EndpointsResolvedConfig, RegionInputConfig, RegionResolvedConfig } from "@aws-sdk/config-resolver";
    import { EventStreamSerdeInputConfig, EventStreamSerdeResolvedConfig } from "@aws-sdk/eventstream-serde-config-resolver";
    import { EventStreamInputConfig, EventStreamResolvedConfig } from "@aws-sdk/middleware-eventstream";
    import { HostHeaderInputConfig, HostHeaderResolvedConfig } from "@aws-sdk/middleware-host-header";
    import { RetryInputConfig, RetryResolvedConfig } from "@aws-sdk/middleware-retry";
    import { WebSocketInputConfig, WebSocketResolvedConfig } from "@aws-sdk/middleware-sdk-transcribe-streaming";
    import { AwsAuthInputConfig, AwsAuthResolvedConfig } from "@aws-sdk/middleware-signing";
    import { UserAgentInputConfig, UserAgentResolvedConfig } from "@aws-sdk/middleware-user-agent";
    import { HttpHandler as __HttpHandler } from "@aws-sdk/protocol-http";
    import { Client as __Client, DefaultsMode, SmithyConfiguration as __SmithyConfiguration, SmithyResolvedConfiguration as __SmithyResolvedConfiguration } from "@aws-sdk/smithy-client";
    import { BodyLengthCalculator as __BodyLengthCalculator, Credentials as __Credentials, Decoder as __Decoder, Encoder as __Encoder, EventStreamPayloadHandlerProvider as __EventStreamPayloadHandlerProvider, EventStreamSerdeProvider as __EventStreamSerdeProvider, HashConstructor as __HashConstructor, HttpHandlerOptions as __HttpHandlerOptions, Logger as __Logger, Provider as __Provider, Provider, RegionInfoProvider, StreamCollector as __StreamCollector, UrlParser as __UrlParser, UserAgent as __UserAgent } from "@aws-sdk/types";
    import { StartMedicalStreamTranscriptionCommandInput, StartMedicalStreamTranscriptionCommandOutput } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartMedicalStreamTranscriptionCommand";
    import { StartStreamTranscriptionCommandInput, StartStreamTranscriptionCommandOutput } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/commands/StartStreamTranscriptionCommand";
    export type ServiceInputTypes = StartMedicalStreamTranscriptionCommandInput | StartStreamTranscriptionCommandInput;
    export type ServiceOutputTypes = StartMedicalStreamTranscriptionCommandOutput | StartStreamTranscriptionCommandOutput;
    export interface ClientDefaults extends Partial<__SmithyResolvedConfiguration<__HttpHandlerOptions>> {
            /**
                * The HTTP handler to use. Fetch in browser and Https in Nodejs.
                */
            requestHandler?: __HttpHandler;
            /**
                * A constructor for a class implementing the {@link __Hash} interface
                * that computes the SHA-256 HMAC or checksum of a string or binary buffer.
                * @internal
                */
            sha256?: __HashConstructor;
            /**
                * The function that will be used to convert strings into HTTP endpoints.
                * @internal
                */
            urlParser?: __UrlParser;
            /**
                * A function that can calculate the length of a request body.
                * @internal
                */
            bodyLengthChecker?: __BodyLengthCalculator;
            /**
                * A function that converts a stream into an array of bytes.
                * @internal
                */
            streamCollector?: __StreamCollector;
            /**
                * The function that will be used to convert a base64-encoded string to a byte array.
                * @internal
                */
            base64Decoder?: __Decoder;
            /**
                * The function that will be used to convert binary data to a base64-encoded string.
                * @internal
                */
            base64Encoder?: __Encoder;
            /**
                * The function that will be used to convert a UTF8-encoded string to a byte array.
                * @internal
                */
            utf8Decoder?: __Decoder;
            /**
                * The function that will be used to convert binary data to a UTF-8 encoded string.
                * @internal
                */
            utf8Encoder?: __Encoder;
            /**
                * The runtime environment.
                * @internal
                */
            runtime?: string;
            /**
                * Disable dyanamically changing the endpoint of the client based on the hostPrefix
                * trait of an operation.
                */
            disableHostPrefix?: boolean;
            /**
                * Value for how many times a request will be made at most in case of retry.
                */
            maxAttempts?: number | __Provider<number>;
            /**
                * Specifies which retry algorithm to use.
                */
            retryMode?: string | __Provider<string>;
            /**
                * Optional logger for logging debug/info/warn/error.
                */
            logger?: __Logger;
            /**
                * Enables IPv6/IPv4 dualstack endpoint.
                */
            useDualstackEndpoint?: boolean | __Provider<boolean>;
            /**
                * Enables FIPS compatible endpoints.
                */
            useFipsEndpoint?: boolean | __Provider<boolean>;
            /**
                * Unique service identifier.
                * @internal
                */
            serviceId?: string;
            /**
                * The AWS region to which this client will send requests
                */
            region?: string | __Provider<string>;
            /**
                * Default credentials provider; Not available in browser runtime.
                * @internal
                */
            credentialDefaultProvider?: (input: any) => __Provider<__Credentials>;
            /**
                * Fetch related hostname, signing name or signing region with given region.
                * @internal
                */
            regionInfoProvider?: RegionInfoProvider;
            /**
                * The function that provides necessary utilities for handling request event stream.
                * @internal
                */
            eventStreamPayloadHandlerProvider?: __EventStreamPayloadHandlerProvider;
            /**
                * The provider populating default tracking information to be sent with `user-agent`, `x-amz-user-agent` header
                * @internal
                */
            defaultUserAgentProvider?: Provider<__UserAgent>;
            /**
                * The function that provides necessary utilities for generating and parsing event stream
                */
            eventStreamSerdeProvider?: __EventStreamSerdeProvider;
            /**
                * The {@link DefaultsMode} that will be used to determine how certain default configuration options are resolved in the SDK.
                */
            defaultsMode?: DefaultsMode | Provider<DefaultsMode>;
    }
    type TranscribeStreamingClientConfigType = Partial<__SmithyConfiguration<__HttpHandlerOptions>> & ClientDefaults & RegionInputConfig & EndpointsInputConfig & RetryInputConfig & HostHeaderInputConfig & AwsAuthInputConfig & EventStreamInputConfig & WebSocketInputConfig & UserAgentInputConfig & EventStreamSerdeInputConfig;
    /**
        * The configuration interface of TranscribeStreamingClient class constructor that set the region, credentials and other options.
        */
    export interface TranscribeStreamingClientConfig extends TranscribeStreamingClientConfigType {
    }
    type TranscribeStreamingClientResolvedConfigType = __SmithyResolvedConfiguration<__HttpHandlerOptions> & Required<ClientDefaults> & RegionResolvedConfig & EndpointsResolvedConfig & RetryResolvedConfig & HostHeaderResolvedConfig & AwsAuthResolvedConfig & EventStreamResolvedConfig & WebSocketResolvedConfig & UserAgentResolvedConfig & EventStreamSerdeResolvedConfig;
    /**
        * The resolved configuration interface of TranscribeStreamingClient class. This is resolved and normalized from the {@link TranscribeStreamingClientConfig | constructor configuration interface}.
        */
    export interface TranscribeStreamingClientResolvedConfig extends TranscribeStreamingClientResolvedConfigType {
    }
    /**
        * <p>Operations and objects for transcribing streaming speech to text.</p>
        */
    export class TranscribeStreamingClient extends __Client<__HttpHandlerOptions, ServiceInputTypes, ServiceOutputTypes, TranscribeStreamingClientResolvedConfig> {
            /**
                * The resolved configuration of TranscribeStreamingClient class. This is resolved and normalized from the {@link TranscribeStreamingClientConfig | constructor configuration interface}.
                */
            readonly config: TranscribeStreamingClientResolvedConfig;
            constructor(configuration: TranscribeStreamingClientConfig);
            /**
                * Destroy underlying resources, like sockets. It's usually not necessary to do this.
                * However in Node.js, it's best to explicitly shut down the client's agent when it is no longer needed.
                * Otherwise, sockets might stay open for quite a long time before the server terminates them.
                */
            destroy(): void;
    }
    export {};
}

declare module '@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/models/models_0' {
    import { ExceptionOptionType as __ExceptionOptionType } from "@aws-sdk/smithy-client";
    import { TranscribeStreamingServiceException as __BaseException } from "@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/models/TranscribeStreamingServiceException";
    /**
        * <p>The entity identified as personally identifiable information (PII).</p>
        */
    export interface Entity {
            /**
                * <p>The start time of speech that was identified as PII.</p>
                */
            StartTime?: number;
            /**
                * <p>The end time of speech that was identified as PII.</p>
                */
            EndTime?: number;
            /**
                * <p>The category of information identified in this entity; for example, PII.</p>
                */
            Category?: string;
            /**
                * <p>The type of PII identified in this entity; for example, name or credit card number.</p>
                */
            Type?: string;
            /**
                * <p>The words in the transcription output that have been identified as a PII entity.</p>
                */
            Content?: string;
            /**
                * <p>A value between zero and one that Amazon Transcribe assigns to PII identified in the source audio. Larger values indicate a higher confidence in PII identification.</p>
                */
            Confidence?: number;
    }
    export namespace Entity {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Entity) => any;
    }
    export enum ItemType {
            PRONUNCIATION = "pronunciation",
            PUNCTUATION = "punctuation"
    }
    /**
        * <p>A word, phrase, or punctuation mark that is transcribed from the input audio.</p>
        */
    export interface Item {
            /**
                * <p>The offset from the beginning of the audio stream to the beginning of the audio that
                *       resulted in the item.</p>
                */
            StartTime?: number;
            /**
                * <p>The offset from the beginning of the audio stream to the end of the audio that resulted in
                *       the item.</p>
                */
            EndTime?: number;
            /**
                * <p>The type of the item. <code>PRONUNCIATION</code> indicates that the item is a word
                *       that was recognized in the input audio. <code>PUNCTUATION</code> indicates that the item
                *       was interpreted as a pause in the input audio.</p>
                */
            Type?: ItemType | string;
            /**
                * <p>The word or punctuation that was recognized in the input audio.</p>
                */
            Content?: string;
            /**
                * <p>Indicates whether a word in the item matches a word in the vocabulary filter you've chosen
                *       for your media stream. If <code>true</code> then a word in the item matches your
                *       vocabulary filter.</p>
                */
            VocabularyFilterMatch?: boolean;
            /**
                * <p>If speaker identification is enabled, shows the speakers identified in the media
                *       stream.</p>
                */
            Speaker?: string;
            /**
                * <p>A value between zero and one for an item that is a confidence score that Amazon Transcribe assigns to each
                *       word or phrase that it transcribes.</p>
                */
            Confidence?: number;
            /**
                * <p>If partial result stabilization has been enabled, indicates whether the word or phrase in
                *       the item is stable. If <code>Stable</code> is <code>true</code>, the result is stable.</p>
                */
            Stable?: boolean;
    }
    export namespace Item {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Item) => any;
    }
    /**
        * <p>A list of possible transcriptions for the audio.</p>
        */
    export interface Alternative {
            /**
                * <p>The text that was transcribed from the audio.</p>
                */
            Transcript?: string;
            /**
                * <p>One or more alternative interpretations of the input audio. </p>
                */
            Items?: Item[];
            /**
                * <p>Contains the entities identified as personally identifiable information (PII) in the transcription output.</p>
                */
            Entities?: Entity[];
    }
    export namespace Alternative {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Alternative) => any;
    }
    /**
        * <p>Provides a wrapper for the audio chunks that you are sending.</p>
        *          <p>For information on audio encoding in Amazon Transcribe, see
        *       <a href="https://docs.aws.amazon.com/transcribe/latest/dg/input.html">Speech input</a>. For information
        *       on audio encoding formats in Amazon Transcribe Medical, see
        *       <a href="https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html">Speech input</a>.</p>
        */
    export interface AudioEvent {
            /**
                * <p>An audio blob that contains the next part of the audio that you want to transcribe. The
                *       maximum audio chunk size is 32 KB.</p>
                */
            AudioChunk?: Uint8Array;
    }
    export namespace AudioEvent {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: AudioEvent) => any;
    }
    /**
        * <p>Represents the audio stream from your application to Amazon Transcribe.</p>
        */
    export type AudioStream = AudioStream.AudioEventMember | AudioStream.$UnknownMember;
    export namespace AudioStream {
            /**
                * <p>A blob of audio from your application. You audio stream consists of one or more audio
                *       events.</p>
                *          <p>For information on audio encoding formats in Amazon Transcribe, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/input.html">Speech input</a>. For
                *       information on audio encoding formats in Amazon Transcribe Medical, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html">Speech input</a>.</p>
                *          <p>For more information on stream encoding in Amazon Transcribe, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html">Event stream encoding</a>. For
                *       information on stream encoding in Amazon Transcribe Medical, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/event-stream-med.html">Event stream encoding</a>.</p>
                */
            interface AudioEventMember {
                    AudioEvent: AudioEvent;
                    $unknown?: never;
            }
            interface $UnknownMember {
                    AudioEvent?: never;
                    $unknown: [string, any];
            }
            interface Visitor<T> {
                    AudioEvent: (value: AudioEvent) => T;
                    _: (name: string, value: any) => T;
            }
            const visit: <T>(value: AudioStream, visitor: Visitor<T>) => T;
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: AudioStream) => any;
    }
    /**
        * <p>One or more arguments to the <code>StartStreamTranscription</code> or
        *         <code>StartMedicalStreamTranscription</code> operation was invalid. For example,
        *         <code>MediaEncoding</code> was not set to a valid encoding, or <code>LanguageCode</code> was
        *       not set to a valid code. Check the parameters and try your request again.</p>
        */
    export class BadRequestException extends __BaseException {
            readonly name: "BadRequestException";
            readonly $fault: "client";
            Message?: string;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<BadRequestException, __BaseException>);
    }
    /**
        * <p>A new stream started with the same session ID. The current stream has been
        *       terminated.</p>
        */
    export class ConflictException extends __BaseException {
            readonly name: "ConflictException";
            readonly $fault: "client";
            Message?: string;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ConflictException, __BaseException>);
    }
    export enum ContentIdentificationType {
            PII = "PII"
    }
    export enum ContentRedactionType {
            PII = "PII"
    }
    /**
        * <p>A problem occurred while processing the audio. Amazon Transcribe or Amazon Transcribe Medical terminated processing. Try
        *       your request again.</p>
        */
    export class InternalFailureException extends __BaseException {
            readonly name: "InternalFailureException";
            readonly $fault: "server";
            Message?: string;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<InternalFailureException, __BaseException>);
    }
    export enum LanguageCode {
            DE_DE = "de-DE",
            EN_AU = "en-AU",
            EN_GB = "en-GB",
            EN_US = "en-US",
            ES_US = "es-US",
            FR_CA = "fr-CA",
            FR_FR = "fr-FR",
            IT_IT = "it-IT",
            JA_JP = "ja-JP",
            KO_KR = "ko-KR",
            PT_BR = "pt-BR",
            ZH_CN = "zh-CN"
    }
    /**
        * <p>The language codes of the identified languages and their associated confidence scores.
        *       The confidence score is a value between zero and one; a larger value indicates a higher
        *       confidence in the identified language.</p>
        */
    export interface LanguageWithScore {
            /**
                * <p>The language code of the language identified by Amazon Transcribe.</p>
                */
            LanguageCode?: LanguageCode | string;
            /**
                * <p>The confidence score for the associated language code. Confidence scores are values
                *       between zero and one; larger values indicate a higher confidence in the identified language.
                *      </p>
                */
            Score?: number;
    }
    export namespace LanguageWithScore {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: LanguageWithScore) => any;
    }
    /**
        * <p>You have exceeded the maximum number of concurrent transcription streams, are starting
        *       transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream
        *       has finished processing, or break your audio stream into smaller chunks and try your request
        *       again.</p>
        */
    export class LimitExceededException extends __BaseException {
            readonly name: "LimitExceededException";
            readonly $fault: "client";
            Message?: string;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<LimitExceededException, __BaseException>);
    }
    export enum MediaEncoding {
            FLAC = "flac",
            OGG_OPUS = "ogg-opus",
            PCM = "pcm"
    }
    /**
        * <p>The medical entity identified as personal health information.</p>
        */
    export interface MedicalEntity {
            /**
                * <p>The start time of the speech that was identified as a medical entity.</p>
                */
            StartTime?: number;
            /**
                * <p>The end time of the speech that was identified as a medical entity.</p>
                */
            EndTime?: number;
            /**
                * <p>The type of personal health information of the medical entity.</p>
                */
            Category?: string;
            /**
                * <p>The word or words in the transcription output that have been identified as a
                *             medical entity.</p>
                */
            Content?: string;
            /**
                * <p>A value between zero and one that Amazon Transcribe Medical assigned to the personal health information
                *             that it identified in the source audio. Larger values indicate that Amazon Transcribe Medical has higher
                *             confidence in the personal health information that it identified.</p>
                */
            Confidence?: number;
    }
    export namespace MedicalEntity {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalEntity) => any;
    }
    /**
        * <p>A word, phrase, or punctuation mark that is transcribed from the input audio.</p>
        */
    export interface MedicalItem {
            /**
                * <p>The number of seconds into an audio stream that indicates the creation time of an
                *             item.</p>
                */
            StartTime?: number;
            /**
                * <p>The number of seconds into an audio stream that indicates the creation time of an
                *             item.</p>
                */
            EndTime?: number;
            /**
                * <p>The type of the item. <code>PRONUNCIATION</code> indicates that the item is a word
                *             that was recognized in the input audio. <code>PUNCTUATION</code> indicates that the item
                *             was interpreted as a pause in the input audio, such as a period to indicate the end of a
                *             sentence.</p>
                */
            Type?: ItemType | string;
            /**
                * <p>The word or punctuation mark that was recognized in the input audio.</p>
                */
            Content?: string;
            /**
                * <p>A value between 0 and 1 for an item that is a confidence score that Amazon Transcribe Medical assigns to
                *             each word that it transcribes.</p>
                */
            Confidence?: number;
            /**
                * <p>If speaker identification is enabled, shows the integer values that correspond to the
                *             different speakers identified in the stream. For example, if the value of
                *                 <code>Speaker</code> in the stream is either a <code>0</code> or a <code>1</code>,
                *             that indicates that Amazon Transcribe Medical has identified two speakers in the stream. The value of
                *                 <code>0</code> corresponds to one speaker and the value of <code>1</code>
                *             corresponds to the other speaker.</p>
                */
            Speaker?: string;
    }
    export namespace MedicalItem {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalItem) => any;
    }
    /**
        * <p>A list of possible transcriptions for the audio.</p>
        */
    export interface MedicalAlternative {
            /**
                * <p>The text that was transcribed from the audio.</p>
                */
            Transcript?: string;
            /**
                * <p>A list of objects that contains words and punctuation marks that represents one or
                *             more interpretations of the input audio.</p>
                */
            Items?: MedicalItem[];
            /**
                * <p>Contains the medical entities identified as personal health information in the transcription output.</p>
                */
            Entities?: MedicalEntity[];
    }
    export namespace MedicalAlternative {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalAlternative) => any;
    }
    export enum MedicalContentIdentificationType {
            PHI = "PHI"
    }
    /**
        * <p>The results of transcribing a portion of the input audio stream.</p>
        */
    export interface MedicalResult {
            /**
                * <p>A unique identifier for the result.</p>
                */
            ResultId?: string;
            /**
                * <p>The time, in seconds, from the beginning of the audio stream to the beginning of the
                *             result.</p>
                */
            StartTime?: number;
            /**
                * <p>The time, in seconds, from the beginning of the audio stream to the end of the
                *             result.</p>
                */
            EndTime?: number;
            /**
                * <p>Amazon Transcribe Medical divides the incoming audio stream into segments at natural points in the audio.
                *             Transcription results are returned based on these segments.</p>
                *         <p>The <code>IsPartial</code> field is <code>true</code> to indicate that Amazon Transcribe Medical has
                *             additional transcription data to send. The <code>IsPartial</code> field is
                *                 <code>false</code> to indicate that this is the last transcription result for the
                *             segment.</p>
                */
            IsPartial?: boolean;
            /**
                * <p>A list of possible transcriptions of the audio. Each alternative typically contains
                *             one <code>Item</code> that contains the result of the transcription.</p>
                */
            Alternatives?: MedicalAlternative[];
            /**
                * <p>When channel identification is enabled, Amazon Transcribe Medical transcribes the speech from each audio
                *             channel separately.</p>
                *         <p>You can use <code>ChannelId</code> to retrieve the transcription results for a single
                *             channel in your audio stream.</p>
                */
            ChannelId?: string;
    }
    export namespace MedicalResult {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalResult) => any;
    }
    /**
        * <p>The medical transcript in a <a>MedicalTranscriptEvent</a>.</p>
        */
    export interface MedicalTranscript {
            /**
                * <p>
                *             <a>MedicalResult</a> objects that contain the results of transcribing a
                *             portion of the input audio stream. The array can be empty.</p>
                */
            Results?: MedicalResult[];
    }
    export namespace MedicalTranscript {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalTranscript) => any;
    }
    /**
        * <p>Represents a set of transcription results from the server to the client. It contains
        *             one or more segments of the transcription.</p>
        */
    export interface MedicalTranscriptEvent {
            /**
                * <p>The transcription of the audio stream. The transcription is composed of all of the
                *             items in the results list.</p>
                */
            Transcript?: MedicalTranscript;
    }
    export namespace MedicalTranscriptEvent {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalTranscriptEvent) => any;
    }
    /**
        * <p>Service is currently unavailable. Try your request later.</p>
        */
    export class ServiceUnavailableException extends __BaseException {
            readonly name: "ServiceUnavailableException";
            readonly $fault: "server";
            Message?: string;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ServiceUnavailableException, __BaseException>);
    }
    /**
        * <p>Represents the transcription result stream from Amazon Transcribe Medical to your application.</p>
        */
    export type MedicalTranscriptResultStream = MedicalTranscriptResultStream.BadRequestExceptionMember | MedicalTranscriptResultStream.ConflictExceptionMember | MedicalTranscriptResultStream.InternalFailureExceptionMember | MedicalTranscriptResultStream.LimitExceededExceptionMember | MedicalTranscriptResultStream.ServiceUnavailableExceptionMember | MedicalTranscriptResultStream.TranscriptEventMember | MedicalTranscriptResultStream.$UnknownMember;
    export namespace MedicalTranscriptResultStream {
            /**
                * <p>A portion of the transcription of the audio stream. Events are sent periodically from
                *             Amazon Transcribe Medical to your application. The event can be a partial transcription of a section of the
                *             audio stream, or it can be the entire transcription of that portion of the audio
                *             stream.</p>
                */
            interface TranscriptEventMember {
                    TranscriptEvent: MedicalTranscriptEvent;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>One or more arguments to the <code>StartStreamTranscription</code> or
                *         <code>StartMedicalStreamTranscription</code> operation was invalid. For example,
                *         <code>MediaEncoding</code> was not set to a valid encoding, or <code>LanguageCode</code> was
                *       not set to a valid code. Check the parameters and try your request again.</p>
                */
            interface BadRequestExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException: BadRequestException;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>You have exceeded the maximum number of concurrent transcription streams, are starting
                *       transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream
                *       has finished processing, or break your audio stream into smaller chunks and try your request
                *       again.</p>
                */
            interface LimitExceededExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException: LimitExceededException;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>A problem occurred while processing the audio. Amazon Transcribe or Amazon Transcribe Medical terminated processing. Try
                *       your request again.</p>
                */
            interface InternalFailureExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException: InternalFailureException;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>A new stream started with the same session ID. The current stream has been
                *       terminated.</p>
                */
            interface ConflictExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException: ConflictException;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>Service is currently unavailable. Try your request later.</p>
                */
            interface ServiceUnavailableExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException: ServiceUnavailableException;
                    $unknown?: never;
            }
            interface $UnknownMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown: [string, any];
            }
            interface Visitor<T> {
                    TranscriptEvent: (value: MedicalTranscriptEvent) => T;
                    BadRequestException: (value: BadRequestException) => T;
                    LimitExceededException: (value: LimitExceededException) => T;
                    InternalFailureException: (value: InternalFailureException) => T;
                    ConflictException: (value: ConflictException) => T;
                    ServiceUnavailableException: (value: ServiceUnavailableException) => T;
                    _: (name: string, value: any) => T;
            }
            const visit: <T>(value: MedicalTranscriptResultStream, visitor: Visitor<T>) => T;
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MedicalTranscriptResultStream) => any;
    }
    export enum PartialResultsStability {
            HIGH = "high",
            LOW = "low",
            MEDIUM = "medium"
    }
    /**
        * <p>The result of transcribing a portion of the input audio stream. </p>
        */
    export interface Result {
            /**
                * <p>A unique identifier for the result. </p>
                */
            ResultId?: string;
            /**
                * <p>The offset in seconds from the beginning of the audio stream to the beginning of the
                *       result.</p>
                */
            StartTime?: number;
            /**
                * <p>The offset in seconds from the beginning of the audio stream to the end of the
                *       result.</p>
                */
            EndTime?: number;
            /**
                * <p>Amazon Transcribe divides the incoming audio stream into segments at natural points in the audio.
                *       Transcription results are returned based on these segments. </p>
                *          <p>The <code>IsPartial</code> field is <code>true</code> to indicate that Amazon Transcribe has
                *       additional transcription data to send, <code>false</code> to indicate that this is the last
                *       transcription result for the segment.</p>
                */
            IsPartial?: boolean;
            /**
                * <p>A list of possible transcriptions for the audio. Each alternative typically contains one
                *       <code>item</code> that contains the result of the transcription.</p>
                */
            Alternatives?: Alternative[];
            /**
                * <p>When channel identification is enabled, Amazon Transcribe transcribes the speech from each audio
                *       channel separately.</p>
                *          <p>You can use <code>ChannelId</code> to retrieve the transcription results for a single
                *       channel in your audio stream.</p>
                */
            ChannelId?: string;
            /**
                * <p>The language code of the identified language in your media stream.</p>
                */
            LanguageCode?: LanguageCode | string;
            /**
                * <p>The language code of the dominant language identified in your media.</p>
                */
            LanguageIdentification?: LanguageWithScore[];
    }
    export namespace Result {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Result) => any;
    }
    export enum Specialty {
            CARDIOLOGY = "CARDIOLOGY",
            NEUROLOGY = "NEUROLOGY",
            ONCOLOGY = "ONCOLOGY",
            PRIMARYCARE = "PRIMARYCARE",
            RADIOLOGY = "RADIOLOGY",
            UROLOGY = "UROLOGY"
    }
    export enum Type {
            CONVERSATION = "CONVERSATION",
            DICTATION = "DICTATION"
    }
    export interface StartMedicalStreamTranscriptionRequest {
            /**
                * <p> Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US
                *             English (en-US). </p>
                */
            LanguageCode: LanguageCode | string | undefined;
            /**
                * <p>The sample rate of the input audio (in Hertz). Amazon Transcribe medical supports a range from
                *             16,000 Hz to 48,000 Hz. Note that the sample rate you specify must match that of your
                *             audio.</p>
                */
            MediaSampleRateHertz: number | undefined;
            /**
                * <p>The encoding used for the input audio.</p>
                */
            MediaEncoding: MediaEncoding | string | undefined;
            /**
                * <p>The name of the medical custom vocabulary to use when processing the real-time
                *             stream.</p>
                */
            VocabularyName?: string;
            /**
                * <p>The medical specialty of the clinician or provider.</p>
                */
            Specialty: Specialty | string | undefined;
            /**
                * <p>The type of input audio. Choose <code>DICTATION</code> for a provider dictating
                *             patient notes. Choose <code>CONVERSATION</code> for a dialogue between a patient and one
                *             or more medical professionanls.</p>
                */
            Type: Type | string | undefined;
            /**
                * <p>When <code>true</code>, enables speaker identification in your real-time
                *             stream.</p>
                */
            ShowSpeakerLabel?: boolean;
            /**
                * <p> Optional. An identifier for the transcription session. If you don't provide a session
                *             ID, Amazon Transcribe generates one for you and returns it in the response. </p>
                */
            SessionId?: string;
            /**
                * <p>Represents the audio stream from your application to Amazon Transcribe.</p>
                */
            AudioStream: AsyncIterable<AudioStream> | undefined;
            /**
                * <p>When <code>true</code>, instructs Amazon Transcribe Medical to process each audio channel separately and
                *             then merge the transcription output of each channel into a single transcription.</p>
                *         <p>Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time,
                *             end time, and any alternative transcriptions.</p>
                *         <p>You can't set both <code>ShowSpeakerLabel</code> and
                *                 <code>EnableChannelIdentification</code> in the same request. If you set both, your
                *             request returns a <code>BadRequestException</code>.</p>
                */
            EnableChannelIdentification?: boolean;
            /**
                * <p>The number of channels that are in your audio stream.</p>
                */
            NumberOfChannels?: number;
            /**
                * <p>Set this field to <code>PHI</code> to identify personal health information in the
                *             transcription output.</p>
                */
            ContentIdentificationType?: MedicalContentIdentificationType | string;
    }
    export namespace StartMedicalStreamTranscriptionRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartMedicalStreamTranscriptionRequest) => any;
    }
    export interface StartMedicalStreamTranscriptionResponse {
            /**
                * <p>An identifier for the streaming transcription.</p>
                */
            RequestId?: string;
            /**
                * <p>The language code for the response transcript. For Amazon Transcribe Medical, this is US English
                *             (en-US).</p>
                */
            LanguageCode?: LanguageCode | string;
            /**
                * <p>The sample rate of the input audio, in Hertz (Hz).</p>
                */
            MediaSampleRateHertz?: number;
            /**
                * <p>The encoding used for the input audio stream.</p>
                */
            MediaEncoding?: MediaEncoding | string;
            /**
                * <p>The name of the vocabulary used when processing the stream.</p>
                */
            VocabularyName?: string;
            /**
                * <p>The specialty in the medical domain.</p>
                */
            Specialty?: Specialty | string;
            /**
                * <p>The type of audio that was transcribed. </p>
                */
            Type?: Type | string;
            /**
                * <p>Shows whether speaker identification was enabled in the stream.</p>
                */
            ShowSpeakerLabel?: boolean;
            /**
                * <p>Optional. An identifier for the transcription session. If you don't provide a session
                *             ID, Amazon Transcribe generates one for you and returns it in the response.</p>
                */
            SessionId?: string;
            /**
                * <p>Represents the stream of transcription events from Amazon Transcribe Medical to your application. </p>
                */
            TranscriptResultStream?: AsyncIterable<MedicalTranscriptResultStream>;
            /**
                * <p>Shows whether channel identification has been enabled in the stream.</p>
                */
            EnableChannelIdentification?: boolean;
            /**
                * <p>The number of channels identified in the stream.</p>
                */
            NumberOfChannels?: number;
            /**
                * <p>If the value is <code>PHI</code>, indicates that you've configured your stream to
                *             identify personal health information.</p>
                */
            ContentIdentificationType?: MedicalContentIdentificationType | string;
    }
    export namespace StartMedicalStreamTranscriptionResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartMedicalStreamTranscriptionResponse) => any;
    }
    export enum VocabularyFilterMethod {
            MASK = "mask",
            REMOVE = "remove",
            TAG = "tag"
    }
    export interface StartStreamTranscriptionRequest {
            /**
                * <p>The language code of the input audio stream.</p>
                */
            LanguageCode?: LanguageCode | string;
            /**
                * <p>The sample rate of the input audio (in Hertz). Low-quality audio, such as telephone
                *       audio, is typically around 8,000 Hz. High-quality audio typically ranges from 16,000 Hz to
                *       48,000 Hz. Note that the sample rate you specify must match that of your audio.</p>
                */
            MediaSampleRateHertz: number | undefined;
            /**
                * <p>The encoding used for the input audio.</p>
                */
            MediaEncoding: MediaEncoding | string | undefined;
            /**
                * <p>The name of the custom vocabulary you want to use with your transcription.</p>
                *          <p>This operation is not intended for use in conjunction with the
                *       <code>IdentifyLanguage</code> operation. If you're using <code>IdentifyLanguage</code>
                *       in your request and want to use one or more custom vocabularies with your transcription, use the
                *       <code>VocabularyNames</code> operation instead.</p>
                */
            VocabularyName?: string;
            /**
                * <p>A identifier for the transcription session. Use this parameter when you want to retry a
                *       session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in
                *       the response.</p>
                */
            SessionId?: string;
            /**
                * <p>PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP/2 data
                *       frame.</p>
                */
            AudioStream: AsyncIterable<AudioStream> | undefined;
            /**
                * <p>The name of the vocabulary filter you want to use with your transcription.</p>
                *          <p>This operation is not intended for use in conjunction with the
                *       <code>IdentifyLanguage</code> operation. If you're using <code>IdentifyLanguage</code>
                *       in your request and want to use one or more vocabulary filters with your transcription, use the
                *       <code>VocabularyFilterNames</code> operation instead.</p>
                */
            VocabularyFilterName?: string;
            /**
                * <p>The manner in which you use your vocabulary filter to filter words in your transcript.
                *       <code>Remove</code> removes filtered words from your transcription results.
                *       <code>Mask</code> masks filtered words with a <code>***</code> in your transcription
                *       results. <code>Tag</code> keeps the filtered words in your transcription results and tags
                *       them. The tag appears as <code>VocabularyFilterMatch</code> equal to
                *       <code>True</code>.</p>
                */
            VocabularyFilterMethod?: VocabularyFilterMethod | string;
            /**
                * <p>When <code>true</code>, enables speaker identification in your media stream.</p>
                */
            ShowSpeakerLabel?: boolean;
            /**
                * <p>When <code>true</code>, instructs Amazon Transcribe to process each audio channel separately,
                *       then merges the transcription output of each channel into a single transcription.</p>
                *          <p>Amazon Transcribe also produces a transcription of each item. An item includes the start time, end
                *       time, and any alternative transcriptions.</p>
                */
            EnableChannelIdentification?: boolean;
            /**
                * <p>The number of channels that are in your audio stream.</p>
                */
            NumberOfChannels?: number;
            /**
                * <p>When <code>true</code>, instructs Amazon Transcribe to present transcription results that have the
                *       partial results stabilized. Normally, any word or phrase from one partial result can change in
                *       a subsequent partial result. With partial results stabilization enabled, only the last few
                *       words of one partial result can change in another partial result.</p>
                */
            EnablePartialResultsStabilization?: boolean;
            /**
                * <p>You can use this field to set the stability level of the transcription results. A higher
                *       stability level means that the transcription results are less likely to change. Higher
                *       stability levels can come with lower overall transcription accuracy.</p>
                */
            PartialResultsStability?: PartialResultsStability | string;
            /**
                * <p>Set this field to PII to identify personally identifiable information (PII) in the transcription
                *       output. Content identification is performed only upon complete transcription of the audio
                *       segments.</p>
                *          <p>You cant set both <code>ContentIdentificationType</code> and
                *       <code>ContentRedactionType</code> in the same request. If you set both, your request
                *       returns a <code>BadRequestException</code>.</p>
                */
            ContentIdentificationType?: ContentIdentificationType | string;
            /**
                * <p>Set this field to PII to redact personally identifiable information (PII) in the transcription
                *       output. Content redaction is performed only upon complete transcription of the audio
                *       segments.</p>
                *          <p>You cant set both <code>ContentRedactionType</code> and
                *       <code>ContentIdentificationType</code> in the same request. If you set both, your request
                *       returns a <code>BadRequestException</code>.</p>
                */
            ContentRedactionType?: ContentRedactionType | string;
            /**
                * <p>List the PII entity types you want to identify or redact. In order to specify entity types,
                *       you must have either <code>ContentIdentificationType</code> or
                *       <code>ContentRedactionType</code> enabled.</p>
                *          <p>
                *             <code>PIIEntityTypes</code> must be comma-separated; the available values are:
                *       <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>,
                *       <code>CREDIT_DEBIT_NUMBER</code>, <code>CREDIT_DEBIT_CVV</code>,
                *       <code>CREDIT_DEBIT_EXPIRY</code>, <code>PIN</code>, <code>EMAIL</code>,
                *       <code>ADDRESS</code>, <code>NAME</code>, <code>PHONE</code>,
                *       <code>SSN</code>, and <code>ALL</code>.</p>
                *          <p>
                *             <code>PiiEntityTypes</code> is an optional parameter with a default value of
                *       <code>ALL</code>.</p>
                */
            PiiEntityTypes?: string;
            /**
                * <p>The name of the language model you want to use.</p>
                */
            LanguageModelName?: string;
            /**
                * <p>Optional. Set this value to <code>true</code> to enable language identification for
                *       your media stream.</p>
                */
            IdentifyLanguage?: boolean;
            /**
                * <p>An object containing a list of languages that might be present in your audio.</p>
                *          <p>You must provide two or more language codes to help Amazon Transcribe identify the correct
                *       language of your media stream with the highest possible accuracy. You can only select one
                *       variant per language; for example, you can't include both <code>en-US</code> and
                *       <code>en-UK</code> in the same request.</p>
                *          <p>You can only use this parameter if you've set <code>IdentifyLanguage</code> to
                *       <code>true</code>in your request.</p>
                */
            LanguageOptions?: string;
            /**
                * <p>Optional. From the subset of languages codes you provided for
                *       <code>LanguageOptions</code>, you can select one preferred language for your
                *       transcription.</p>
                *          <p>You can only use this parameter if you've set <code>IdentifyLanguage</code> to
                *       <code>true</code>in your request.</p>
                */
            PreferredLanguage?: LanguageCode | string;
            /**
                * <p>The names of the custom vocabularies you want to use with your transcription.</p>
                *          <p>Note that if the custom vocabularies you specify are in languages that don't match the
                *       language identified in your media, your job fails.</p>
                *          <p>This operation is only intended for use in conjunction with the
                *       <code>IdentifyLanguage</code> operation. If you're not using <code>IdentifyLanguage</code>
                *       in your request and want to use a custom vocabulary with your transcription, use the
                *       <code>VocabularyName</code> operation instead.</p>
                */
            VocabularyNames?: string;
            /**
                * <p>The names of the vocabulary filters you want to use with your transcription.</p>
                *          <p>Note that if the vocabulary filters you specify are in languages that don't match the
                *        language identified in your media, your job fails.</p>
                *          <p>This operation is only intended for use in conjunction with the
                *        <code>IdentifyLanguage</code> operation. If you're not using <code>IdentifyLanguage</code>
                *        in your request and want to use a vocabulary filter with your transcription, use the
                *        <code>VocabularyFilterName</code> operation instead.</p>
                */
            VocabularyFilterNames?: string;
    }
    export namespace StartStreamTranscriptionRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartStreamTranscriptionRequest) => any;
    }
    /**
        * <p>The transcription in a <a>TranscriptEvent</a>.</p>
        */
    export interface Transcript {
            /**
                * <p>
                *             <a>Result</a> objects that contain the results of transcribing a portion of the
                *       input audio stream. The array can be empty.</p>
                */
            Results?: Result[];
    }
    export namespace Transcript {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Transcript) => any;
    }
    /**
        * <p>Represents a set of transcription results from the server to the client. It contains one
        *       or more segments of the transcription.</p>
        */
    export interface TranscriptEvent {
            /**
                * <p>The transcription of the audio stream. The transcription is composed of all of the items
                *       in the results list.</p>
                */
            Transcript?: Transcript;
    }
    export namespace TranscriptEvent {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: TranscriptEvent) => any;
    }
    /**
        * <p>Represents the transcription result stream from Amazon Transcribe to your application.</p>
        */
    export type TranscriptResultStream = TranscriptResultStream.BadRequestExceptionMember | TranscriptResultStream.ConflictExceptionMember | TranscriptResultStream.InternalFailureExceptionMember | TranscriptResultStream.LimitExceededExceptionMember | TranscriptResultStream.ServiceUnavailableExceptionMember | TranscriptResultStream.TranscriptEventMember | TranscriptResultStream.$UnknownMember;
    export namespace TranscriptResultStream {
            /**
                * <p>A portion of the transcription of the audio stream. Events are sent periodically from
                *       Amazon Transcribe to your application. The event can be a partial transcription of a section of the audio
                *       stream, or it can be the entire transcription of that portion of the audio stream. </p>
                */
            interface TranscriptEventMember {
                    TranscriptEvent: TranscriptEvent;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>A client error occurred when the stream was created. Check the parameters of the request
                *       and try your request again.</p>
                */
            interface BadRequestExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException: BadRequestException;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>Your client has exceeded one of the Amazon Transcribe limits, typically the limit on audio length.
                *       Break your audio stream into smaller chunks and try your request again.</p>
                */
            interface LimitExceededExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException: LimitExceededException;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>A problem occurred while processing the audio. Amazon Transcribe terminated processing.</p>
                */
            interface InternalFailureExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException: InternalFailureException;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>A new stream started with the same session ID. The current stream has been
                *       terminated.</p>
                */
            interface ConflictExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException: ConflictException;
                    ServiceUnavailableException?: never;
                    $unknown?: never;
            }
            /**
                * <p>Service is currently unavailable. Try your request later.</p>
                */
            interface ServiceUnavailableExceptionMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException: ServiceUnavailableException;
                    $unknown?: never;
            }
            interface $UnknownMember {
                    TranscriptEvent?: never;
                    BadRequestException?: never;
                    LimitExceededException?: never;
                    InternalFailureException?: never;
                    ConflictException?: never;
                    ServiceUnavailableException?: never;
                    $unknown: [string, any];
            }
            interface Visitor<T> {
                    TranscriptEvent: (value: TranscriptEvent) => T;
                    BadRequestException: (value: BadRequestException) => T;
                    LimitExceededException: (value: LimitExceededException) => T;
                    InternalFailureException: (value: InternalFailureException) => T;
                    ConflictException: (value: ConflictException) => T;
                    ServiceUnavailableException: (value: ServiceUnavailableException) => T;
                    _: (name: string, value: any) => T;
            }
            const visit: <T>(value: TranscriptResultStream, visitor: Visitor<T>) => T;
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: TranscriptResultStream) => any;
    }
    export interface StartStreamTranscriptionResponse {
            /**
                * <p>An identifier for the transcription.</p>
                */
            RequestId?: string;
            /**
                * <p>The language code of the input audio stream.</p>
                */
            LanguageCode?: LanguageCode | string;
            /**
                * <p>The sample rate, in Hertz (Hz), for the input audio stream.</p>
                */
            MediaSampleRateHertz?: number;
            /**
                * <p>The encoding used for the input audio stream.</p>
                */
            MediaEncoding?: MediaEncoding | string;
            /**
                * <p>The name of the custom vocabulary used when processing the stream.</p>
                */
            VocabularyName?: string;
            /**
                * <p>An identifier for a specific transcription session.</p>
                */
            SessionId?: string;
            /**
                * <p>Represents the stream of transcription events from Amazon Transcribe to your application.</p>
                */
            TranscriptResultStream?: AsyncIterable<TranscriptResultStream>;
            /**
                * <p>The name of the vocabulary filter used when processing the stream.</p>
                */
            VocabularyFilterName?: string;
            /**
                * <p>The vocabulary filtering method used when processing the stream.</p>
                */
            VocabularyFilterMethod?: VocabularyFilterMethod | string;
            /**
                * <p>Shows whether speaker identification was enabled in the transcription.</p>
                */
            ShowSpeakerLabel?: boolean;
            /**
                * <p>Shows whether channel identification was enabled in the stream.</p>
                */
            EnableChannelIdentification?: boolean;
            /**
                * <p>The number of channels identified in the stream.</p>
                */
            NumberOfChannels?: number;
            /**
                * <p>Shows whether partial results stabilization was enabled in the transcription.</p>
                */
            EnablePartialResultsStabilization?: boolean;
            /**
                * <p>If partial results stabilization has been enabled in the stream, shows the stability
                *       level.</p>
                */
            PartialResultsStability?: PartialResultsStability | string;
            /**
                * <p>Shows whether content identification was enabled in this stream.</p>
                */
            ContentIdentificationType?: ContentIdentificationType | string;
            /**
                * <p>Shows whether content redaction was enabled in this stream.</p>
                */
            ContentRedactionType?: ContentRedactionType | string;
            /**
                * <p>Lists the PII entity types you specified in your request.</p>
                */
            PiiEntityTypes?: string;
            /**
                * <p>The name of the custom language model used in the transcription.</p>
                */
            LanguageModelName?: string;
            /**
                * <p>The language code of the language identified in your media stream.</p>
                */
            IdentifyLanguage?: boolean;
            /**
                * <p>The language codes used in the identification of your media stream's predominant
                *       language.</p>
                */
            LanguageOptions?: string;
            /**
                * <p>The preferred language you specified in your request.</p>
                */
            PreferredLanguage?: LanguageCode | string;
            /**
                * <p>The name of the custom vocabulary used when processing the stream.</p>
                */
            VocabularyNames?: string;
            /**
                * <p>The name of the vocabulary filter used when processing the stream.</p>
                */
            VocabularyFilterNames?: string;
    }
    export namespace StartStreamTranscriptionResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartStreamTranscriptionResponse) => any;
    }
}

declare module '@aws-sdk/client-transcribe-streaming/node_modules/@aws-sdk/client-transcribe-streaming/dist-types/models/TranscribeStreamingServiceException' {
    import { ServiceException as __ServiceException, ServiceExceptionOptions as __ServiceExceptionOptions } from "@aws-sdk/smithy-client";
    /**
        * Base exception class for all service exceptions from TranscribeStreaming service.
        */
    export class TranscribeStreamingServiceException extends __ServiceException {
            /**
                * @internal
                */
            constructor(options: __ServiceExceptionOptions);
    }
}

